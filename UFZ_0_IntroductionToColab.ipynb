{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alanbseo/FlickrWorkshopUFZ/blob/master/UFZ_0_IntroductionToColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIIoNJvzjJi3",
    "colab_type": "text"
   },
   "source": [
    "Whenever the CoLab runtime is reset (it can happen unexpectedly, esp. you are away from the screen for a while), we need to run this set-up script again to get the data ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0wNuauCx-IG",
    "colab_type": "text"
   },
   "source": [
    "Google Colab is a Jupiter notebook service released in October 2017. Colab can work with a web browser without any installation and easy to share notebooks with other users.  \n",
    "\n",
    "- You can use the GPU for free\n",
    "  - Either in Edit > Notebook settings or Runtime>Change runtime type, you can select GPU as Hardware accelerator.\n",
    "- It supports Python2 and Python3 Most of the Deep Learning (DL) libraries like Tensorflow, keras, matplotlib, scikit-learn, and pandas are pre-installed.\n",
    "![GPU setting](https://cdn-images-1.medium.com/max/1600/1*WNovJnpGMOys8Rv7YIsZzA.png)\n",
    "\n",
    "- You can install the required packages and configure the environment in the code cell. This alleviates the need to configure the environment the same when multiple people with different environments collaborate.\n",
    "- It supports Markdown and it can be shared and edited like Google Docs or Google Spreadsheets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CC624f-GjGOb",
    "colab_type": "code",
    "outputId": "de8d0707-5ac5-4d9b-a26a-01baf80304c3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mFlickrWorkshopData\u001b[0m/  \u001b[01;34mMask_RCNN\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
      "FlickrWorkshopData  Mask_RCNN  sample_data\n"
     ]
    }
   ],
   "source": [
    "%ls /content\n",
    "\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab1gItRizz35",
    "colab_type": "text"
   },
   "source": [
    "See whehter GPU works properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "etD0RSojywSo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M9LWs-Hsz4Z3",
    "colab_type": "code",
    "outputId": "bde6a8c8-8149-4332-eb9d-3eb28e5848a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 22 09:45:08 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.43       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    70W / 149W |   7902MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Thk1wUpIjc7J",
    "colab_type": "text"
   },
   "source": [
    "Colab's runs in a virtual machine, which resets itself after a period of idle time, so it has to be configured again each time. Therefore, when you work with Colab, you need to carefully prepare the necessary package installation and configuration code. Also, when learning a deep learning model using the GPU, for which the learning time can be quite long, the virtual machine may be reset during learning. Therefore, long learning should be done by local or other cloud GPU instances. \n",
    "\n",
    "The Colab service limits the number of times it can run to avoid excessive resource consumption. If something is wrong, you can reset the virtual machine yourself by clicking \"Runtime\"> \"Reset All Runtime\".  If the reset fails, try again later.\n",
    "\n",
    "References: \n",
    "https://research.google.com/colaboratory/local-runtimes.html\n",
    "https://colab.research.google.com/notebooks/welcome.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FdcOnDVJi52g",
    "colab_type": "code",
    "outputId": "dc2960af-6e79-42c5-8ddb-9a78ea7810f1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         359G   24G  317G   7% /\n",
      "tmpfs           6.4G     0  6.4G   0% /dev\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
      "tmpfs           6.4G   12K  6.4G   1% /var/colab\n",
      "/dev/sda1       365G   27G  339G   8% /opt/bin\n",
      "shm             6.0G     0  6.0G   0% /dev/shm\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
      "['.config', 'FlickrWorkshopData', 'Mask_RCNN', 'sample_data']\n",
      "FlickrWorkshopData  Mask_RCNN  sample_data\n"
     ]
    }
   ],
   "source": [
    "# some trivial system commands.. \n",
    "\n",
    "import sys\n",
    "sys.version_info  \n",
    "\n",
    "!df -h # disk usage\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "print(os.listdir()) # list dir\n",
    "!ls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZEPC67o72Rnf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "print(os.path.abspath(\".\")) #print the current path \n",
    "!pwd                        #print the current path \n",
    "print(os.getcwd())          #print the current working directory \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgOjgGhx0PcR",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6E9xuwBRjBj8",
    "colab_type": "code",
    "outputId": "58c17a61-2c19-433a-ab1d-999de5ea9d8e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# check the version \n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "UFZ_0_IntroductionToColab.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
